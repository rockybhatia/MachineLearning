{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give an input string this method replaces all the single letter words with empty string,\n",
    "# basically removing them from the resultant string.\n",
    "\n",
    "def mask_single_letters(text):\n",
    "    filtered_string = re.sub(r'\\b([a-zA-Z]{1})\\b', \"\", text)\n",
    "    return filtered_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give an input string this method replaces all the single letter words with empty string,\n",
    "# basically removing them from the resultant string.\n",
    "\n",
    "def mask_escape_sequences(text):\n",
    "    # Mask string fragments like \\x<nn>\n",
    "    filtered_string = re.sub(r'\\\\x[a-z]{0,2}[0-9]{0,2}', \" \", text)\n",
    "    \n",
    "    # Mask string fragments for escape sequences like \\a \\b \\t \\n\n",
    "    filtered_string = re.sub(r'\\\\a+', \"\", filtered_string)\n",
    "    filtered_string = re.sub(r'\\\\b+', \"\", filtered_string)\n",
    "    filtered_string = re.sub(r'\\\\t+', \" \", filtered_string)\n",
    "    filtered_string = re.sub(r'\\\\n+', \" \", filtered_string)\n",
    "    \n",
    "    return filtered_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask all numbers\n",
    "def mask_numbers(text):\n",
    "    filtered_string = re.sub(r'[0-9]+', \"\", text)\n",
    "    return filtered_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a final string consisting only of all the words containing letters from a-z and A-Z\n",
    "def mask_non_alphabet_words(text):\n",
    "    filtered_list = re.findall(r'\\b([a-zA-Z]+)\\b', text, re.M)\n",
    "    filtered_string = ' '.join(filtered_list)\n",
    "    return filtered_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask email addresses\n",
    "def mask_email(text):\n",
    "    filtered_string = re.sub(r'\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b', \"\", text)\n",
    "    return filtered_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    stemmer = LancasterStemmer()\n",
    "    stems = []\n",
    "    for word in text.split():\n",
    "        stem = stemmer.stem(word)\n",
    "        stems.append(stem)\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmas = []\n",
    "    for word in text.split():\n",
    "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
    "        lemmas.append(lemma)\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided a string, this method creates and returns a set containing all the unique words in the passed string.\n",
    "\n",
    "def unique_words_str(text):\n",
    "    result = set([])\n",
    "    for word in text.split():\n",
    "        result.add(word)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided a list of strings, this method creates and returns a set containing all the unique words in the passed list.\n",
    "\n",
    "def unique_words_list(data):\n",
    "    result = set([])\n",
    "    for word in data:\n",
    "        result.add(word)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_stopwords(text, words_to_remove, case_sensitive=True):\n",
    "    filtered = []\n",
    "    \n",
    "    if(case_sensitive == False):\n",
    "        stopwords = [item.lower() for item in words_to_remove]\n",
    "        for word in text.split():\n",
    "            if word.lower() not in words_to_remove:\n",
    "                filtered.append(word)\n",
    "    else:\n",
    "        stopwords = words_to_remove\n",
    "        for word in text.split():\n",
    "            if word not in words_to_remove:\n",
    "                filtered.append(word)\n",
    "    return ' '.join(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    filtered_text = mask_escape_sequences(text)\n",
    "    filtered_text = mask_email(filtered_text)\n",
    "    filtered_text = mask_numbers(filtered_text)\n",
    "    filtered_text = mask_non_alphabet_words(filtered_text)\n",
    "    filtered_text = mask_single_letters(filtered_text)\n",
    "    filtered_text = mask_stopwords(filtered_text, stopwords.words('english'))\n",
    "    #filtered_text = stem(filtered_text)\n",
    "    filtered_text = lemmatize(filtered_text)\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"resume_data.csv\", index_col=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Resume'] = dataset['Resume'].map(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset['Resume'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('resume_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
